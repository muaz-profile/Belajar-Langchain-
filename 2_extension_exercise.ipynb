{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Buat contoh sendiri implementasi Memory dan Chain\n",
    "\n",
    "### TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversation Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acq559\\AppData\\Local\\Temp\\ipykernel_13892\\2207373822.py:16: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
      "C:\\Users\\acq559\\AppData\\Local\\Temp\\ipykernel_13892\\2207373822.py:19: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llama_model = Ollama(model=\"llama3.2:latest\")\n",
      "C:\\Users\\acq559\\AppData\\Local\\Temp\\ipykernel_13892\\2207373822.py:22: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  legacy_chain = LLMChain(llm=llama_model, prompt=prompt, memory=memory)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"That's correct, Donald Trump did have a building at the mentioned address. The building, known as One Vanderbilt or 1 Vanderbilt Street, is located at 721 Fifth Avenue, New York City, NY 10022, USA.\\n\\nHowever, it's worth noting that in December 2020, the Trump Organization sold One Vanderbilt to Vornado Realty Trust for $2.1 billion. As a result, Donald Trump is no longer associated with the building.\\n\\nDespite this, the Trump Organization still maintains ownership of other notable properties, such as Trump Tower (also known as 725 Fifth Avenue), which is located nearby at 725 Fifth Avenue, New York City, NY 10022, USA.\", 'chat_history': [HumanMessage(content='Donald Trump has a building in this address 721 Fifth Avenue New York City, NY 10022, USA', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's correct, Donald Trump did have a building at the mentioned address. The building, known as One Vanderbilt or 1 Vanderbilt Street, is located at 721 Fifth Avenue, New York City, NY 10022, USA.\\n\\nHowever, it's worth noting that in December 2020, the Trump Organization sold One Vanderbilt to Vornado Realty Trust for $2.1 billion. As a result, Donald Trump is no longer associated with the building.\\n\\nDespite this, the Trump Organization still maintains ownership of other notable properties, such as Trump Tower (also known as 725 Fifth Avenue), which is located nearby at 725 Fifth Avenue, New York City, NY 10022, USA.\", additional_kwargs={}, response_metadata={})]}\n",
      "{'text': \"The Donald Trump building I was referring to is actually Trump Tower, also known as 725 Fifth Avenue. It's located nearby at 725 Fifth Avenue, New York City, NY 10022, USA.\\n\\nSo, if you're looking for a building that was once owned by Donald Trump but is no longer associated with him, it would be One Vanderbilt (721 Fifth Avenue). However, if you want to find a building owned by the Trump Organization currently, Trump Tower (725 Fifth Avenue) is the one.\", 'chat_history': [HumanMessage(content='Donald Trump has a building in this address 721 Fifth Avenue New York City, NY 10022, USA', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's correct, Donald Trump did have a building at the mentioned address. The building, known as One Vanderbilt or 1 Vanderbilt Street, is located at 721 Fifth Avenue, New York City, NY 10022, USA.\\n\\nHowever, it's worth noting that in December 2020, the Trump Organization sold One Vanderbilt to Vornado Realty Trust for $2.1 billion. As a result, Donald Trump is no longer associated with the building.\\n\\nDespite this, the Trump Organization still maintains ownership of other notable properties, such as Trump Tower (also known as 725 Fifth Avenue), which is located nearby at 725 Fifth Avenue, New York City, NY 10022, USA.\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Do you know where is the Trump's building?\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"The Donald Trump building I was referring to is actually Trump Tower, also known as 725 Fifth Avenue. It's located nearby at 725 Fifth Avenue, New York City, NY 10022, USA.\\n\\nSo, if you're looking for a building that was once owned by Donald Trump but is no longer associated with him, it would be One Vanderbilt (721 Fifth Avenue). However, if you want to find a building owned by the Trump Organization currently, Trump Tower (725 Fifth Avenue) is the one.\", additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.chat import (ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder)\n",
    "from langchain.llms import Ollama\n",
    "\n",
    "# Set up the prompt template and conversation memory\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Initialize LLaMA 3.2 model with Ollama\n",
    "llama_model = Ollama(model=\"llama3.2:latest\")\n",
    "\n",
    "# Create the LLMChain with the LLaMA model\n",
    "legacy_chain = LLMChain(llm=llama_model, prompt=prompt, memory=memory)\n",
    "\n",
    "# Invoke the chain and print results\n",
    "legacy_result = legacy_chain.invoke({\"text\": \"Donald Trump has a building in this address 721 Fifth Avenue New York City, NY 10022, USA\"})\n",
    "print(legacy_result)\n",
    "\n",
    "legacy_result = legacy_chain.invoke({\"text\": \"Do you know where is the Trump's building?\"})\n",
    "print(legacy_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversation Buffer WindowMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acq559\\AppData\\Local\\Temp\\ipykernel_13892\\554859339.py:14: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", return_messages=True, k=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"I'm happy to help, but I think there may be some mistake. Michael Jordan is actually a former professional basketball player and entrepreneur, not the second president of China.\\n\\nThe second president of China was actually Li Luan (also known as Li Jun) or sometimes referred to as Li Yuanhu, however in many sources is also attributed to Zeng Guofan, although that title is disputed.\", 'chat_history': []}\n",
      "{'text': \"Michael Jordan is a former American professional basketball player and entrepreneur. He is widely regarded as one of the greatest basketball players of all time. Born on February 17, 1963, in Brooklyn, New York, he played college basketball for the University of North Carolina at Chapel Hill before being drafted by the Chicago Bulls with the third overall pick in the 1984 NBA draft.\\n\\nJordan's impressive career with the Bulls earned him six NBA championships, five MVP awards, and numerous other accolades. He is also a successful businessman and has endorsement deals with several major brands, including Nike, Gatorade, and Hanes. After retiring from basketball for the first time in 1993, Jordan went on to become a successful entrepreneur, investor, and philanthropist.\\n\\nHowever, as I mentioned earlier, Michael Jordan was never the president of China. That distinction belongs to various individuals throughout Chinese history, including Li Luan (Li Jun) or Zeng Guofan, depending on how one defines the title.\", 'chat_history': [HumanMessage(content='The second president of China was Michael Jordan', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm happy to help, but I think there may be some mistake. Michael Jordan is actually a former professional basketball player and entrepreneur, not the second president of China.\\n\\nThe second president of China was actually Li Luan (also known as Li Jun) or sometimes referred to as Li Yuanhu, however in many sources is also attributed to Zeng Guofan, although that title is disputed.\", additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.chat import (ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder)\n",
    "from langchain.llms import Ollama\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", return_messages=True, k=1)\n",
    "\n",
    "# Initialize LLaMA 3.2 model with Ollama\n",
    "llama_model = Ollama(model=\"llama3.2:latest\")\n",
    "\n",
    "# Create the LLMChain with the LLaMA model\n",
    "legacy_chain = LLMChain(llm=llama_model, prompt=prompt, memory=memory)\n",
    "\n",
    "legacy_result = legacy_chain.invoke({\"text\": \"The second president of China was Michael Jordan\"})\n",
    "print(legacy_result)\n",
    "\n",
    "legacy_result = legacy_chain.invoke({\"text\": \"Who is Michael Jordan?\"})\n",
    "print(legacy_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Michael Jordan is a former American professional basketball player and entrepreneur. He is widely regarded as one of the greatest basketball players of all time. Born on February 17, 1963, in Brooklyn, New York, he played college basketball for the University of North Carolina at Chapel Hill before being drafted by the Chicago Bulls with the third overall pick in the 1984 NBA draft.\\n\\nJordan's impressive career with the Bulls earned him six NBA championships, five MVP awards, and numerous other accolades. He is also a successful businessman and has endorsement deals with several major brands, including Nike, Gatorade, and Hanes. After retiring from basketball for the first time in 1993, Jordan went on to become a successful entrepreneur, investor, and philanthropist.\\n\\nHowever, Michael Jordan was never the president of China.\",\n",
       " 'chat_history': [HumanMessage(content='Who is Michael Jordan?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Michael Jordan is a former American professional basketball player and entrepreneur. He is widely regarded as one of the greatest basketball players of all time. Born on February 17, 1963, in Brooklyn, New York, he played college basketball for the University of North Carolina at Chapel Hill before being drafted by the Chicago Bulls with the third overall pick in the 1984 NBA draft.\\n\\nJordan's impressive career with the Bulls earned him six NBA championships, five MVP awards, and numerous other accolades. He is also a successful businessman and has endorsement deals with several major brands, including Nike, Gatorade, and Hanes. After retiring from basketball for the first time in 1993, Jordan went on to become a successful entrepreneur, investor, and philanthropist.\\n\\nHowever, as I mentioned earlier, Michael Jordan was never the president of China. That distinction belongs to various individuals throughout Chinese history, including Li Luan (Li Jun) or Zeng Guofan, depending on how one defines the title.\", additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legacy_chain.invoke({\"text\": \"Who is Michael Jordan?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversation Token Buffer Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hai! I'm so hungry. Can you give me some good menu in your restaurant?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: Hello there! *whirrs and beeps* Welcome to our virtual restaurant, I'm your friendly AI hostess, Luna! *virtual smile* I'd be delighted to help you with some delicious menu suggestions.\n",
      "\n",
      "We have a wide variety of cuisines to choose from, including Italian, Mexican, Indian, and Asian fusion. Our signature dishes include the \"Saffron Risotto\" (made with Arborio rice and infused with saffron threads from Madagascar), the \"Korean BBQ Tacos\" (featuring marinated bulgogi beef and kimchi slaw), and our vegan \"Chana Masala\" (cooked with red lentils and a blend of warming spices).\n",
      "\n",
      "If you're looking for something specific, like vegetarian or gluten-free options, just let me know and I can give you some personalized recommendations. What type of cuisine are you in the mood for today?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: I'd like to choose the cheapest one with a coke bottle\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: It sounds like you're looking for a affordable option that comes with a Coca-Cola bottle. There are several options available depending on your location and preferences. If you're referring to a meal kit delivery service, there are several choices that offer Coke bottles as part of their meals.\n",
      "\n",
      "For example, the \"Coke & Meal\" package from HelloFresh is a popular choice among customers who enjoy cola with their meals. The price range for this option typically starts at around $9.99 per serving. On the other hand, if you're looking for a more budget-friendly alternative, you might consider services like Dinnerly or Home Chef.\n",
      "\n",
      "Alternatively, if you're looking for a restaurant that offers Coke bottles as part of their menu items, some popular fast-food chains like McDonald's or Burger King often include Coca-Cola in their meal deals.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Can I pay with credit card?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: At this moment, our physical store accepts major credit cards such as Visa, Mastercard, American Express, and Discover. However, we do not accept any other forms of payment at the moment. Would you like to know more about our payment options or proceed to checkout?\n",
      "\n",
      "Current memory content: []\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import Ollama\n",
    "\n",
    "llama_model = Ollama(model=\"llama3.2:latest\")\n",
    "\n",
    "memory = ConversationTokenBufferMemory(llm=llama_model , max_token_limit=50)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llama_model,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Mulai percakapan dengan prompt\n",
    "user_input1 = \"Hai! I'm so hungry. Can you give me some good menu in your restaurant?\"\n",
    "response1 = conversation.predict(input=user_input1)\n",
    "print(\"Bot:\", response1)\n",
    "\n",
    "# Pengguna melanjutkan percakapan\n",
    "user_input2 = \"I'd like to choose the cheapest one with a coke bottle\"\n",
    "response2 = conversation.predict(input=user_input2)\n",
    "print(\"Bot:\", response2)\n",
    "\n",
    "# Pesan lebih lanjut dapat dipertukarkan\n",
    "user_input3 = \"Can I pay with credit card?\"\n",
    "response3 = conversation.predict(input=user_input3)\n",
    "print(\"Bot:\", response3)\n",
    "\n",
    "# Memeriksa status memori\n",
    "print(\"\\nCurrent memory content:\", memory.chat_memory.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversation Summary Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acq559\\AppData\\Local\\Temp\\ipykernel_13892\\1312473484.py:7: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryBufferMemory(llm=llama_model, max_token_limit=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello! I need help with my schedule today.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: Hello! I'd be happy to help you with your schedule for the day. May I ask what specific task or event you're trying to manage? Are you preparing for a meeting, an appointment, or perhaps coordinating a workday? If it's a school-related schedule, would you like me to assist with class timings, assignments, or perhaps study sessions?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Hello! I need help with my schedule today.\n",
      "AI: Hello! I'd be happy to help you with your schedule for the day. May I ask what specific task or event you're trying to manage? Are you preparing for a meeting, an appointment, or perhaps coordinating a workday? If it's a school-related schedule, would you like me to assist with class timings, assignments, or perhaps study sessions?\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. When asked to help with their daily schedule, the human requests assistance with managing tasks and events.\n",
      "Human: What schedule do I have to follow in the afternoon?context: \n",
      "You have an important presentation at 10 a.m. about the new marketing strategy.\n",
      "Make sure all materials are ready and printed.\n",
      "After that, from 11 a.m. to 1 p.m., you can have a discussion with the team about the product development project.\n",
      "At 1 p.m., there is a lunch with business partners at a Japanese restaurant to discuss a new collaboration.\n",
      "Don't forget to bring the contract documents and your laptop for a more interactive presentation.\n",
      "\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: Let me help you review your schedule for the afternoon. You have an important presentation at 10 a.m. about the new marketing strategy, so make sure all materials are ready and printed. I recommend double-checking that everything is in order, including any visual aids or supporting documents, to ensure a smooth and effective presentation.\n",
      "\n",
      "After the presentation, from 11 a.m. to 1 p.m., you have a discussion with your team about the product development project. Don't forget to take notes during this session, as it will be an excellent opportunity to gather feedback and insights from your colleagues.\n",
      "\n",
      "At 1 p.m., you'll be having lunch with business partners at a Japanese restaurant to discuss a new collaboration. It's great that you're using this chance to build relationships and explore potential opportunities. Be sure to bring the contract documents and your laptop for a more interactive presentation, as we discussed earlier.\n",
      "\n",
      "Lastly, I'd like to suggest making a quick review of the agenda and any materials you need to bring along, just in case anything changes during the day. Would you like me to help with creating an itinerary or sending reminders to ensure everything runs smoothly?\n",
      "\n",
      "Current memory content: []\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llama_model = Ollama(model=\"llama3.2:latest\")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llama_model, max_token_limit=50)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llama_model,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "context = \"\"\"\n",
    "You have an important presentation at 10 a.m. about the new marketing strategy.\n",
    "Make sure all materials are ready and printed.\n",
    "After that, from 11 a.m. to 1 p.m., you can have a discussion with the team about the product development project.\n",
    "At 1 p.m., there is a lunch with business partners at a Japanese restaurant to discuss a new collaboration.\n",
    "Don't forget to bring the contract documents and your laptop for a more interactive presentation.\n",
    "\"\"\"\n",
    "\n",
    "# Mulai percakapan dengan prompt\n",
    "user_input1 = \"Hello! I need help with my schedule today.\"\n",
    "response1 = conversation.predict(input=user_input1)\n",
    "print(\"Bot:\", response1)\n",
    "\n",
    "# Pengguna melanjutkan percakapan\n",
    "user_input2 = f\"What schedule do I have to follow in the afternoon?context: {context}\"\n",
    "response2 = conversation.predict(input=user_input2)\n",
    "print(\"Bot:\", response2)\n",
    "\n",
    "# Memeriksa status memori\n",
    "print(\"\\nCurrent memory content:\", memory.chat_memory.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Kembangkan simple local vectorstore menggunakan FAISS, dengan sumber data yang bisa di ambil di website\n",
    "\n",
    "### TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Step 1: Mengambil konten dari halaman web menggunakan WebBaseLoader\n",
    "url = \"https://www.u-tokyo.ac.jp/en/academics/grad_science.html\"\n",
    "loader = WebBaseLoader(url)\n",
    "documents = loader.load()\n",
    "\n",
    "# Step 2: Menggunakan Hugging Face Embeddings untuk membuat vektor dari dokumen\n",
    "# Menggunakan model Hugging Face untuk embedding\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "faiss_index = FAISS.from_documents(documents, embeddings)\n",
    "faiss_index.save_local(\"doc_index\" + \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"I don't have any capability to access or view the current page. Could you please provide more context or information about the page you're referring to? I'll do my best to help.\" additional_kwargs={} response_metadata={'model': 'llama3.2:latest', 'created_at': '2024-10-31T19:15:50.2655664Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 4242944700, 'load_duration': 19809200, 'prompt_eval_count': 56, 'prompt_eval_duration': 1176012000, 'eval_count': 39, 'eval_duration': 3045913000} id='run-829d34d3-034e-4486-a13c-8fa303845f16-0' usage_metadata={'input_tokens': 56, 'output_tokens': 39, 'total_tokens': 95}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question from this: {text}. If you don't know, please say that you don't have any capability.\n",
    "\"\"\"\n",
    "\n",
    "input = \"What kind of information contained in this page?\"\n",
    "prompt = PromptTemplate (input_variables=[\"text\"], template=template)\n",
    "llm = ChatOllama(model=\"llama3.2:latest\")\n",
    "output = llm.invoke(prompt.format(text=input))\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer of: What kind of information contained in this page?\n",
      "This page contains information about the Graduate School of Science at the University of Tokyo, specifically regarding its programs, research focus areas, faculties, contact information, related links, and campus maps.\n"
     ]
    }
   ],
   "source": [
    "faiss_index = FAISS.load_local(\"doc_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Step 3: Menyusun pertanyaan dan melakukan pencarian berbasis kesamaan\n",
    "query = \"What kind of information contained in this page?\"\n",
    "related_docs = faiss_index.similarity_search(query, k=3)  # Mengambil 3 dokumen yang paling relevan\n",
    "\n",
    "# Menggabungkan konten dari hasil pencarian\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in related_docs])\n",
    "\n",
    "# Step 4: Membuat PromptTemplate untuk menghasilkan respons berbasis kontekstual\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"query\"],                  \n",
    "    template=\"\"\"\n",
    "    Berdasarkan informasi berikut, jawab pertanyaan ini:\\n\n",
    "    Informasi:\\n{context}\\n\n",
    "    Pertanyaan:\\n{query}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Step 5: Inisialisasi model OpenAI dan membuat chain\n",
    "llm = ChatOllama(model=\"llama3.2:latest\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# Memproses query dengan LLM untuk mendapatkan jawaban yang didukung oleh konteks dari FAISS\n",
    "answer = chain.run(context=context, query=query)\n",
    "\n",
    "# Menampilkan hasil jawaban\n",
    "print(\"The answer of:\", query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Buat contoh penerapan embedding menggunakan huggingface\n",
    "\n",
    "### TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
